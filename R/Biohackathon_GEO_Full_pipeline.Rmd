---
title: "BioHackathon 2017"
output:
  html_notebook: default
---

---

#### Contents:

* [Introduction](#introduction)
* [Accessing GEO Data: No Raw Data Availible](#data1)
    * [Create Expression Dataset](#eset1)
    * [Data Pre-Processing](#preprc1)
* [Accessing GEO Data: Raw Data Available](#data2)
    * [Affymetrix](#affy)
    * [Illumina](#illum)
    * [Agilent](#agil)
* [Differential Expression Analysis](#dea)
* [Retrieving Metadata](#metadata)
* [Workflow Reproduciblity](#repo)



---
    
<a name="introduction"/> 

## Introduction
This script is designed to download and process data from [GEO](https://www.ncbi.nlm.nih.gov/geo/). For each downloaded data set, the data is processed and converted into an expression matrix (rows are genes and columns are samples). Additionally, using the [GEO Metadata Database](https://www.ncbi.nlm.nih.gov/geo/info/geo_paccess.html) specific features for each data set are collected and kept for downstream processing. Prior to running differential expression analysis, the expression data is verified to ensure both normalization and log transformation had been performed. The RNA-seq data is put through additional verification to ensure that it has been run through [voom](http://web.mit.edu/~r/current/arch/i386_linux26/lib/R/library/limma/html/voom.html). This additional step permits the same limma pipeline to be used for both processed microarray and RNA-seq data ([Law et al., 2014](https://www.ncbi.nlm.nih.gov/pubmed/24485249), [limma user guide](http://bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf)).


```{r message=FALSE, warning=FALSE}
# load needed libraries
library(annotate)
library(Biobase)
library(data.table)
library(EMA)
library(GEOmetadb)
library(GEOquery)
library(ggplot2)
library(gplots)
library(knitr)
library(latex2exp)
library(limma)
library(mygene)
library(RColorBrewer)
library(R.utils)
```

<a name="data1"/>   

## Accessing GEO Data: No Raw Data Availible
When there is no raw data available on GEO, the GEO Data Set (GDS) SOFT files are downloaded and processed. If the GSE Accession identifier does not have a corresponding GSD the GSE matrix can be downloaded and the expression data and annotation file it contains can be re-analyzed. In these scenarios, the data are analyzed with caution and all pre-processing steps described by the authors are verified in an attempt to make the analysis pipeline across platforms as consistent as possible.
```{r warning=FALSE, message=FALSE, eval=FALSE, cache=FALSE}
## Download Data
id <- 'GDS2080'

#Download GDS file, put it in the current directory, and load it:
url <- paste('ftp://ftp.ncbi.nlm.nih.gov/geo/datasets/',
             stringr::str_sub(id, 1,4),
             'nnn/', 
             id,
             '/soft/',
             id,
             '.soft.gz', 
             sep = '')

# create directory to download data to
dir.create(paste('Raw_GEO_Data/',id, sep=''))

# download data to directory
utils::download.file(url, destfile=paste('Raw_GEO_Data/', id, '/', id, '.soft.gz', sep=''), mode='wb')

# open GDS
gds <- GEOquery::getGEO(filename=paste('Raw_GEO_Data/', id, '/', id, '.soft.gz', sep=''))

## GSE Data
# Use the getGEO() function to download the GEO data for the id
id = 'GSE10588'
assign(paste(id, '_gse_data', sep = ''), 
       GEOquery::getGEO(id, GSEMatrix=TRUE, AnnotGPL=FALSE))
gse_data <- GSE10588_gse_data

# create gene expression set. If multiple data sets, take the first one and retrieve platform-specific annotation information
if (length(gse_data) > 1) idx <- grep(gse_data[[1]]@annotation, attr(gse_data, 'names')) else idx <- 1
```

<a name="eset1"/> 

### Create Expression Set
Create an expression set from the extracted data extracted from GEO. Additionally, this step also  accesses sample group assignment information from the downloaded GSE matrix.
```{r warning=FALSE, message=FALSE, eval=FALSE, cache=FALSE}
## GDS
# print column names
colnames(GEOquery::Table(gds))

# get experimental data
eset <- GDS2eSet(gds, do.log2=FALSE)
exprs <- Biobase::exprs(eset)

# get gene annotation information
fset <- Biobase::fData(eset)
GSE_genes = fset[,c(1, 4, 3)]
names(GSE_genes) = c('Genes.identifier', 'Genes.ENTREZID', 'Genes.SYMBOL')

## GSE
# view dataset information
gse_exp_set <- gse_data[[idx]]
gse_exp_set

# update column names
Biobase::fvarLabels(gse_exp_set) <- make.names(Biobase::fvarLabels(gse_exp_set))

# convert expression set to expression matrix
exprs_data <- Biobase::exprs(gse_exp_set)

# store gene names and samples
GSE_genes = data.frame(rownames(exprs_data), 
                       gse_data[[1]]@featureData@data$GeneID,
                       gse_data[[1]]@featureData@data$`Gene Symbol`)

# name columns
names(GSE_genes) = c('probe', 'Genes.ENTREZID', 'Genes.SYMBOL')
samples = colnames(exprs_data)

# set group membership for all samples
# GSE43942
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$source_name_ch1), function(x) ifelse(length(grep('norm', x)) == 1, 'control', 'PE')))

# GSE4707
# get sample grouping information
groups <- as.data.frame(Biobase::pData(eset)[-1][1], stringsAsFactors=FALSE)
groups <- as.character(groups[,1])

# rename
groups = as.character(lapply(groups, function(x) ifelse(length(grep('early', x)) == 1, 'EO', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('late', x)) == 1, 'LO', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('normal', x)) == 1, 'Control', x)))

# print groups
table(groups)
```


<a name="preproc1"/>  

### Pre-Processing and Quality Control
Prior to determining which genes are differentially expressed, the preprocessing performed by the submitter of the data is verified. Specifically, the data is checked to ensure normalization and log transformation. For example, if in the data have been pre-processed with RMAExpress then the data should have had convolution background correction, quantile normalization, and summarization using median polish. This also indicates that the expression values are on $log_{2}$ scale. Additional verification performed on the data includes checking for 'NA' values, removing duplicate genes, filtering out lowly expressed genes, and verifying sample clustering.
```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
## log-transformation
# preview data - verify that the data has been log 2 transformed
avg <- base::rowMeans(exprs)
summary(avg)

# if aglient, then data needs to be converted back to log 2 from log 10
exprs_data <- base::log(10**exprs, 2)

## check for NA values
cat('There are', base::sum(!complete.cases(exprs_data)) , 'rows with NA values')
exprs_data_cut = exprs_data[complete.cases(exprs_data), ]

## data normalization
# create box plots to verify pre-processing
boxplot(exprs_data_cut, col = brewer.pal(9, 'Set1'), 
        cex.axis = 0.5, cex.lab = 0.65, las=2,
        ylab = TeX('$log_{2}$ Intensity'))

# remove duplicate gene names
cat('There are', dim(exprs_data_cut)[1], 'genes before removing duplicates')
exprs_data_clean = exprs_data_cut[!duplicated(rownames(exprs_data_cut)),]
cat('There are', dim(exprs_data_clean)[1], 'genes after removing', dim(exprs_data_cut)[1]-dim(exprs_data_clean)[1], 'duplicates')

## filtering
# summarize average gene expression values
avg <- rowMeans(exprs_data_clean)
sum = summary(avg)

# filter out genes that "aren't expressed" - will appear red in the plot
cutoff <- sum[2][[1]] # remove genes below first quantile
exprs_data_clean = expFilter(exprs_data_clean, 
                     threshold = round(sum[2][[1]], 4))

# remove genes below first quantile
cat('There are', dim(exprs_data_clean)[1], 'genes after removing', dim(affy.norm.exprs)[1]-dim(exprs_data_clean)[1], 'when filtering out genes with expresison values below the first quartile')
```

If the expression data have been both normalized and log transformed the samples will have similar $log_{2}$ intensity distributions (first plot). If the data has been filtered the distribution should appear somewhat 'normal' (second plot).  

```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# cluster expression data by sample
sample = EMA::clustering(data = exprs_data_clean, metric = 'pearson', method = 'average')
EMA::clustering.plot(tree = sample, lab = groups, title = 'Filtered Data', scale='row', legend.pos = 'topleft')
```

```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
## Principle Components Analysis
# segment variation into different components
acp = EMA::runPCA(t(exprs_data_clean), scale = FALSE, lab.sample = groups, plotSample = FALSE, plotInertia = FALSE)
names(acp$eig) = c('eigen', '%var', 'cumm %var')

# print results
knitr::kable(head(acp$eig))

# view variation between samples
EMA::plotSample(acp, axes = c(1, 2), lab = groups)

# save cleaned expression data
exp = as.data.frame(cbind(rownames(exprs_data_clean), exprs_data_clean))
names(exp) = c('probe', colnames(exprs_data_clean))
write.table(exp, file = paste('GEO_Data/', id, '_clean_exp_data.txt', sep = ''), 
            sep = '\t',
            row.names = FALSE,
            col.names = TRUE,
            quote = FALSE)
```
Samples appear to cluster by their grouping providing evidence that the set of genes may be differentially expressed.  


<a name="data2"/>   

## Accessing GEO Data: Raw Data Availible
When there is raw data available on GEO, the supplementary data for each study are downloaded and processed. Raw data for each study are stored in a directory named after the study's GSE Accession identifier.
```{r warning=FALSE, message=FALSE, eval=FALSE, cache=FALSE}
## Download Data
id <- 'GSE74341'
url <- paste('https://www.ncbi.nlm.nih.gov/geo/download/?acc=', id, '&format=file', sep = '')
utils::download.file(url, destfile=paste('Raw_GEO_Data/', id, '_RAW.tar', sep=''), mode='wb')
  
# unzip data to directory, where directory has same name as id
utils::untar(paste('Raw_GEO_Data/', id, '_RAW.tar', sep=''), exdir = base::paste('Raw_GEO_Data/', id, sep=''))

# delete zipped file
base::file.remove(paste('Raw_GEO_Data/', id, '_RAW.tar', sep=''))
```

### Get Target Information  
As most of the studies on GEO do not contain files containing target information, this information must be extracted from each study's Geo Study Matrix. The code below is designed to specifically extract sample label information that can be used to create the groupings for differential expression analysis.
```{r warning=FALSE, message=FALSE, eval=FALSE, cache=FALSE}
# download GSE study data
gse_data <- GEOquery::getGEO(id, GSEMatrix=TRUE, AnnotGPL=FALSE)

# take the first and retrieve platform-specific annotation information
if (length(gse_data) > 1) idx <- grep(gse_data[[1]]@annotation, attr(gse_data, 'names')) else idx <- 1

# view dataset information
gse_exp_set <- gse_data[[idx]]
gse_exp_set

# GSE6573, GSE14722, GSE73374, GSE30186
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$title), function(x) ifelse(length(grep('CON', x)) == 1, 'control', 'PE')))

#GSE44711
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$title), function(x) ifelse(length(grep('eclamp', x)) == 1, 'PE', 'control')))

#GSE24129
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$title), function(x) ifelse(length(grep('Norm', x)) == 1, 'control', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('Fetal', x)) == 1, 'FGR', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('Pre-', x)) == 1, 'PE', x)))

# GSE25906
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$characteristics_ch1.2), function(x) ifelse(length(grep('preeclamp', x)) == 1, 'PE', 'control')))

# GSE35574
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$characteristics_ch1.2), function(x) ifelse(length(grep('CON', x)) == 1, 'control', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('IUG', x)) == 1, 'IUGR', x)))
groups = as.character(lapply(groups, function(x) ifelse(length(grep('PE', x)) == 1, 'PE', x)))

# GSE60438
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$source_name_ch1), function(x) ifelse(length(grep('norm', x)) == 1, 'control', 'PE')))

# create groups
# GSE47187
groups = base::rep(c('control', 'PE'), 5)

#GSE74341
groups = c('control', 'EOPE', 'control', 'EOPE', 'control', 'EOPE', 'control', 'EOPE', 'control', 'EOPE', 'control', 'EOPE', 'control', 'EOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'LOPE', 'control', 'term', 'control', 'term', 'control', 'term', 'control', 'term', 'control', 'term', 'control', 'preterm', 'control', 'preterm', 'control', 'preterm', 'control', 'preterm', 'control', 'preterm')

# GSE10588
groups = as.character(lapply(as.character(gse_exp_set@phenoData@data$title), function(x) ifelse(length(grep('preeclampsia', x)) == 1, 'SPE', 'control')))

# print groups
table(groups)
```


<a name="affy"/> 

### Process Affymetrix Data
Downloaded CEL files for each study utilizing Affymetrix are stored in folders and named after the study GSE Accession identifier. The CEL files within each study-specific directory are converted to an AffyBatch object and normalized, background corrected, and $log_2$ transformed using Affy or Oligo RMA. Filtering was also performed and all genes with expression levels below the first quartile are removed. The general workflow for processing Affymetrix data described in the [limma User Guide](http://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf) was used.
```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# load libraries
library(affy)
library(affycoretools)
library(oligo)
library(hgu133plus2.db) #GSE6573
library(hgu133a.db) #GSE14722
library(hgu133b.db) #GSE14722
library(hugene10sttranscriptcluster.db) #GSE24129
library(hugene20sttranscriptcluster.db) # GSE73374

# import CEL files + read into AffyBatch
CEL.files <- base::list.files(path = paste('Raw_GEO_Data/', id, sep=''), full.names=TRUE)
affy.data = affy::ReadAffy(filenames = CEL.files)

# for Affymetrix Human Gene 2.0 ST Array
affy.data = oligo::read.celfiles(CEL.files)
affy.norm = oligo::rma(affy.data)

## normalize the data
affy.norm = affy::rma(affy.data)
affy.norm.exprs = Biobase::exprs(affy.norm)

# normalized intensity values boxplot
graphics::boxplot(affy.norm.exprs, col = brewer.pal(9, 'Set1'), 
        cex.axis = 0.5, cex.lab = 0.65, las=2,
        ylab = TeX('$log_{2}$ Intensity'))

## filtering
# summarize average gene expression values
avg <- rowMeans(affy.norm.exprs)
sum = summary(avg)

# filter out genes that "aren't expressed" - will appear red in the plot
cutoff <- sum[2][[1]] # remove genes below first quantile
exp_filt = expFilter(affy.norm.exprs, threshold = round(sum[2][[1]], 4))

# remove genes below first quantile
cat('There are', dim(exp_filt)[1], 'genes after removing', dim(affy.norm.exprs)[1]-dim(exp_filt)[1], 'when filtering out genes with expresison values below the first quartile')

# cluster expression data by sample
sample = EMA::clustering(data = exp_filt, metric = 'pearson', method = 'average')
EMA::clustering.plot(tree = sample, lab = groups, title = 'Filtered Data', scale='row', legend.pos = 'topleft')

## Principle Components Analysis
# segment variation into different components
acp = EMA::runPCA(t(exp_filt), scale = FALSE, lab.sample = groups, plotSample = FALSE, plotInertia = FALSE)
names(acp$eig) = c('eigen', '%var', 'cumm %var')

# print results
knitr::kable(head(acp$eig))

# view variation between samples
EMA::plotSample(acp, axes = c(1, 2), lab = groups)

# save cleaned expression data
exp = as.data.frame(cbind(rownames(exp_filt), exp_filt))
names(exp) = c('probe', colnames(exp_filt))
write.table(exp, file = paste('GEO_Data/', id, '_clean_exp_data.txt', sep = ''), 
            sep = '\t',
            row.names = FALSE,
            col.names = TRUE,
            quote = FALSE)

# rename saved file
exprs_data_clean = exp_filt

## annotate probes
# print columns
columns(hugene20sttranscriptcluster.db)

# annotate genes
genes_annot <- AnnotationDbi::select(hugene20sttranscriptcluster.db, 
                               keys=rownames(exprs_data_clean),
                               columns=c('SYMBOL', 'ENTREZID'), 
                               keytype='PROBEID')

# GSE73374
genes_a <- affycoretools::annotateEset(oligo::rma(affy.data, target="core"), pd.hugene.2.0.st)

genes_annot <- AnnotationDbi::select(hugene20sttranscriptcluster.db, 
                            keys=as.character(genes_a@featureData@data$PROBEID),
                               columns=c('SYMBOL', 'ENTREZID'), 
                               keytype='PROBEID')


# aggregate 1:many mappings into single list
entrez = aggregate(ENTREZID ~ PROBEID, 
                   data = genes_annot, 
                   paste, collapse = ' /// ')

symbol = aggregate(SYMBOL ~ PROBEID, 
                   data = genes_annot, 
                   paste, collapse = ' /// ')

# merge lists together
genes = merge(entrez, symbol, by = 'PROBEID', all = TRUE)
```


<a name="illum"/> 

### Process Illumina Data
Downloaded non-normalized text files for each study utilizing Illumina are stored in folders and named after the study GSE Accession identifier. Each text file contains a probe summary profile. Processing Illumina data requires a few extra steps, specifically, we must know which files represent targets and which represent controls prior to reading in the data. The text files within each study-specific directory are converted to an Elist object and quantile normalized, background corrected using negative controls, and $log_2$ transformed. Filtering was also performed and all genes with expression levels below the first quartile are removed. The general workflow for processing BeadArray data described in the [limma User Guide](http://www.bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf) was used.
```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# load libraries
library(illuminaHumanv2.db)
library(illuminaHumanv4.db)

# import text files
txt.files <- base::list.files(path = paste('Raw_GEO_Data/', id, sep=''), full.names=TRUE)


# read in probes to access probe names
probes = utils::read.table(txt.files, sep = '\t', header = TRUE)

# read in non-normalized data
illum.data = limma::read.ilmn(txt.files)

## Background Correction
illum.data.bkg  <- limma::backgroundCorrect(illum.data, method="normexp", normexp.method = 'rma')

# create expression data set
illum.bkg.exprs <- illum.data.bkg@.Data[[2]]
rownames(illum.bkg.exprs) <- as.character(probes[,1])

## Normalization
illum.bkg.exprs.norm  <- limma::normalizeQuantiles(illum.bkg.exprs, ties=TRUE)

## Log2 Transformation
illum.bkg.exprs.norm.lg <- base::log(illum.bkg.exprs.norm, 2)

# normalized intensity values boxplot
graphics::boxplot(illum.bkg.exprs.norm.lg, col = brewer.pal(9, 'Set1'), 
        cex.axis = 0.5, cex.lab = 0.65, las=2,
        ylab = TeX('$log_{2}$ Intensity'))

## filtering
# summarize average gene expression values
avg <- rowMeans(illum.bkg.exprs.norm.lg)
sum = summary(avg)

# filter out genes that "aren't expressed" - will appear red in the plot
cutoff <- sum[2][[1]] # remove genes below first quantile
exp_filt = expFilter(illum.bkg.exprs.norm.lg, threshold = round(sum[2][[1]], 4))

# remove genes below first quantile
cat('There are', dim(exp_filt)[1], 'genes after removing', dim(affy.norm.exprs)[1]-dim(exp_filt)[1], 'when filtering out genes with expresison values below the first quartile')

# cluster expression data by sample
sample = EMA::clustering(data = exp_filt, metric = 'pearson', method = 'average')
EMA::clustering.plot(tree = sample, lab = groups, title = 'Filtered Data', scale='row', legend.pos = 'topleft')

## Principle Components Analysis
# segment variation into different components
acp = EMA::runPCA(t(exp_filt), scale = FALSE, lab.sample = groups, plotSample = FALSE, plotInertia = FALSE)
names(acp$eig) = c('eigen', '%var', 'cumm %var')

# print results
knitr::kable(head(acp$eig))

# view variation between samples
EMA::plotSample(acp, axes = c(1, 2), lab = groups)

# save cleaned expression data
exp = as.data.frame(cbind(rownames(exp_filt), exp_filt))
names(exp) = c('probe', colnames(exp_filt))
write.table(exp, file = paste('GEO_Data/', id, '_clean_exp_data.txt', sep = ''), 
            sep = '\t',
            row.names = FALSE,
            col.names = TRUE,
            quote = FALSE)

# rename saved file
exprs_data_clean = exp_filt

# Annotate Probes
# print columns
columns(illuminaHumanv2.db)

# annotate genes
genes_annot <- AnnotationDbi::select(illuminaHumanv3.db, 
                               keys=rownames(exprs_data_clean),
                               columns=c('SYMBOL', 'ENTREZID'), 
                               keytype='PROBEID')

# GSE73374
genes_a <- affycoretools::annotateEset(oligo::rma(affy.data, target="core"), pd.hugene.2.0.st)

genes_annot <- AnnotationDbi::select(hugene20sttranscriptcluster.db, 
                            keys=as.character(genes_a@featureData@data$PROBEID),
                               columns=c('SYMBOL', 'ENTREZID'), 
                               keytype='PROBEID')


# aggregate 1:many mappings into single list
entrez = aggregate(ENTREZID ~ PROBEID, 
                   data = genes_annot, 
                   paste, collapse = ' /// ')

symbol = aggregate(SYMBOL ~ PROBEID, 
                   data = genes_annot, 
                   paste, collapse = ' /// ')

# merge lists together
genes = merge(entrez, symbol, by = 'PROBEID', all = TRUE)
```


<a name="agil"/> 

### Process Agilent Data
Downloaded raw text files for each study utilizing Agilent are stored in folders and named after the study GSE Accession identifier. In addition to the data files a targets text file is included. The text files within each study-specific directory are converted to an RGList object and loess normalized, background corrected, and $log_2$ transformed. Filtering was also performed and all genes with expression levels below the first quartile are removed. The general workflow for processing BeadArray data described in the [limma User Guide](http://matticklab.com/index.php?title=Two_channel_analysis_of_Agilent_microarray_data_with_Limma) and the [Mattick Lab Wiki](http://matticklab.com/index.php?title=Two_channel_analysis_of_Agilent_microarray_data_with_Limma).
```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# import targets
targets <- limma::readTargets(paste('Raw_GEO_Data/', id, '/targets.txt', sep=''))
targets

# load in data as an RG object
RG <- limma::read.maimages(targets, 
                           path=paste('Raw_GEO_Data/', id, sep=''),
                           source="agilent.median")

## Background
agil.data.bkg <- limma::backgroundCorrect(RG, method="normexp", normexp.method = 'rma')

## Normalize
agil.bkg.norm <- limma::normalizeWithinArrays(agil.data.bkg, method="loess")

# average replicate spots
agil.bkg.norm.avg <- avereps(agil.bkg.norm, 
                              ID=agil.bkg.norm$genes$ProbeName)

# probes
probes = agil.bkg.norm.avg$genes$ProbeName

# extract log transformed expression matrix - green/red (aka control/PE)
agil.bkg.norm.avg.lg.exprs = limma::exprs.MA(agil.bkg.norm.avg)

# label expression matrix rows
rownames(agil.bkg.norm.avg.lg.exprs) <- probes

# normalized intensity values boxplot
graphics::boxplot(agil.bkg.norm.avg.lg.exprs, col = brewer.pal(9, 'Set1'), 
        cex.axis = 0.5, cex.lab = 0.65, las=2,
        ylab = TeX('$log_{2}$ Intensity'))

## filtering
# summarize average gene expression values
avg <- rowMeans(agil.bkg.norm.avg.lg.exprs)
sum = summary(avg)

# filter out genes that "aren't expressed" - will appear red in the plot
cutoff <- sum[2][[1]] # remove genes below first quantile
exp_filt = expFilter(agil.bkg.norm.avg.lg.exprs, 
                     threshold = round(sum[2][[1]], 4))

# remove genes below first quantile
cat('There are', dim(exp_filt)[1], 'genes after removing', dim(affy.norm.exprs)[1]-dim(exp_filt)[1], 'when filtering out genes with expresison values below the first quartile')

# cluster expression data by sample
sample = EMA::clustering(data = exp_filt, metric = 'pearson', method = 'average')
EMA::clustering.plot(tree = sample, lab = groups, title = 'Filtered Data', scale='row', legend.pos = 'topleft')

## Principle Components Analysis
# segment variation into different components
acp = EMA::runPCA(t(exp_filt), scale = FALSE, lab.sample = groups, plotSample = FALSE, plotInertia = FALSE)
names(acp$eig) = c('eigen', '%var', 'cumm %var')

# print results
knitr::kable(head(acp$eig))

# view variation between samples
EMA::plotSample(acp, axes = c(1, 2), lab = groups)

# save cleaned expression data
exp = as.data.frame(cbind(rownames(exp_filt), exp_filt))
names(exp) = c('probe', colnames(exp_filt))
write.table(exp, file = paste('GEO_Data/', id, '_clean_exp_data.txt', sep = ''), 
            sep = '\t',
            row.names = FALSE,
            col.names = TRUE,
            quote = FALSE)

# rename saved file
exprs_data_clean = exp_filt

# Annotate Probes
# read in annotation file downloaded from Agilent (9/4/2017)
agilent_annotations.db <- read.table('RAW_GEO_Data/014850_D_AA_20070207.txt',
                                     header = TRUE,
                                     stringsAsFactors = FALSE,
                                     fill = TRUE,
                                     sep = "\t")
# print columns
names(agilent_annotations.db)

# aggregate 1:many mappings into single list
entrez = aggregate(EntrezGeneID ~ ProbeID, 
                   data = agilent_annotations.db, 
                   paste, collapse = ' /// ')

symbol = aggregate(GeneSymbol ~ ProbeID, 
                   data = agilent_annotations.db, 
                   paste, collapse = ' /// ')

# merge lists together
genes = merge(entrez, symbol, by = 'ProbeID', all = TRUE)[-1,]
```



```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# load libraries
library(ABarray)

## create data file
# list files in a directory
file_list <- base::list.files(path = paste('Raw_GEO_Data/', id, '/raw_data', sep=''), full.names=TRUE)

# merge all files in the directory into a single data frame
for (file in file_list){

  # if the merged dataset doesn't exist, create it
  if (!base::exists("combined_ABI_data")){
    combined_ABI_data <- utils::read.table(file, header=TRUE, sep="\t")
    combined_ABI_data$file <- rep(file, nrow(combined_ABI_data))
  }
   
  # if the merged dataset does exist, append to it
  if (base::exists("combined_ABI_data")){
    temp_dataset <- utils::read.table(file, header=TRUE, sep="\t")
    temp_dataset$file <- rep(file, nrow(temp_dataset))
    combined_ABI_data <- base::rbind(combined_ABI_data, temp_dataset)
    base::rm(temp_dataset)
  }
}

# update dataframe to only include certain columns in a specific order
vars <- names(combined_ABI_data) %in% c("Gene_ID", "Probe_ID", "Signal", "Flags", "S_N")

# subset folder
up_combo_data <- combined_ABI_data[vars]

# rename folder columns
base::names(up_combo_data) <- c("geneID", "probeID", "Signal", "Flags", "S/N")

# write file to directory
utils::write.table(up_combo_data,
            paste('Raw_GEO_Data/', id, '/merged_datafile.txt', sep=''),
            row.names = FALSE, 
            quote = FALSE,
            sep = '\t')

## create the experimental design file
# subset data to only include unqiue file and assay names
exp_info <- unique(combined_ABI_data[c("file", "Assay_Name")])

# remove spaces from strings
exp_info$Assay_Name <- unique(gsub(" ", "_", exp_info$Assay_Name))

# add grouping information (only hard-coded bc working on the airplane)
tissue <- c(rep('control', 11), rep('PE', 1), rep('control', 15), rep('PE', 16))

# combine exp info into dataframe
exp_info_grp <- cbind(exp_info, tissue)
names(exp_info_grp) <- c("sampleName", "assayName", "group")

# write file to directory
utils::write.table(exp_info_grp,
            paste('Raw_GEO_Data/', id, '/merged_exp_info.txt', sep=''),
            row.names = FALSE, 
            quote = FALSE,
            sep = '\t')

## Analyze data
eset = ABarray(paste('Raw_GEO_Data/', id, '/merged_datafile.txt', sep=''), 
               paste('Raw_GEO_Data/', id, '/merged_exp_info.txt', sep=''), "group")

```

<a name="dea"/>  

### Differential Expression Analysis
Differential expression analysis was performed on the pre-processed microarray data using limma ( [microarray](http://bioconductor.org/packages/release/bioc/vignettes/limma/inst/doc/usersguide.pdf)).
```{r cache=FALSE, echo=TRUE, error = FALSE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# create design matrix
design <- stats::model.matrix(~ groups + 0, data.frame(exprs_data_clean))
colnames(design) <- gsub('groups', '', colnames(design))
design

# create constrast (the one we subtract is control, then we interpret results for cases)
contr.matrix <- limma::makeContrasts(
   EOvsC = EO-Control,
   LOvsC = LO-Control,
   levels = colnames(design))
contr.matrix

# fit model
fit <- limma::lmFit(data.frame(exprs_data_clean), design)
fit <- limma::contrasts.fit(fit, contrasts=contr.matrix)
efit <- limma::eBayes(fit)

# include only those genes that still exist after pre-processing
rownames(genes) = genes[,1]
GSE_genes <- genes[rownames(exprs_data_clean),]

# add gene information to efit
efit$genes <- GSE_genes

# print number of up and down regulated genes between the samples
top_dec_test <- decideTests(efit)
knitr::kable(summary(top_dec_test))

## Process Results
limma::write.fit(efit, top_dec_test, adjust='BH', file=paste('DE_Results/', id ,'_DEgenes.txt', sep = ''))
```
The plot shows the up (red) and down (green) regulated differentially expressed genes between the samples.  

```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
## Visualize results
# MD plot
plotMD(efit, column=1, status=top_dec_test[,1], main=colnames(efit)[1], cex = 0.7)

# volcano plot
ggplot2::theme_update(plot.title = element_text(hjust = 0.5))
ggplot2::ggplot(data = results, aes(x = results$logFC, y = -log10(results$adj.P.Val)), colour = none) + 
       geom_point(alpha = 0.4, size = 1.75) + 
       labs(title = paste(id, ': Volcano Plot', sep = ' ')) + 
       xlim(c(ceiling(-max(results$logFC)), ceiling(max(results$logFC)))) + 
       ylim(c(0, ceiling(max(-log10(results$adj.P.Val))))) +
       ylab(TeX('$-log_{10}$ P-Value')) + 
       xlab(TeX('$log_{2}$ Fold Change'))
```

```{r cache=FALSE, echo=TRUE, vmessage=FALSE, warning=FALSE, eval=TRUE}
# heatmap - top 100 genes
mvgenes = as.character(rownames(results)[1:100])
c.sample <- EMA::clustering(data = exprs_data_clean[mvgenes, ], metric = 'pearson', method = 'ward')
c.gene <- EMA::clustering(data = t(exprs_data_clean[mvgenes, ]), metric = 'pearson', method = 'ward')
EMA::clustering.plot(tree = c.sample, tree.sup = c.gene, data = exprs_data_clean[mvgenes, 
    ], names.sup = FALSE, lab = groups, trim.heatmap = 0.99, scale = 'row')
```




<a name="metadata"/> 

## GEO Metadata Retrieval
The GEO Metadata Database is used to retrieve important metadata about GEO data sets used in the current analysis. Specifically, the GES Accession identifier, study type (i.e., expression profiling by array, Expression profiling by high throughput sequencing), PubMed identifier, and the original date that the data was submitted to GEO.
```{r warning=FALSE, cache=FALSE}
# save metadata as data.frame
metadata = do.call(rbind, lapply(gds@header, data.frame, stringsAsFactors=FALSE))
colnames(metadata) <- id

# print metadata
knitr::kable(metadata)

# to create groups
gds@dataTable@columns$disease.state
```


<a name="repo"/>  

#### Session Information
```{r eval=TRUE}
sessionInfo()
```